import datetime
from airflow.utils.dates import days_ago
from airflow import DAG
from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': days_ago(1),
    # 'queue': 'edge-01.tdp',  # Add the 'queue' parameter here
}

dag = DAG(
    dag_id='spark_submit_operator_dag',
    default_args=default_args,
    description='A DAG to run SparkPi on YARN using SparkSubmitOperator',
    schedule_interval=datetime.timedelta(days=1),
    start_date=datetime.datetime(2023, 3, 28),
    catchup=False,
)

submit_application = SparkSubmitOperator(
    task_id='submit_application',
    application='/opt/tdp/spark/examples/jars/spark-examples_2.11-2.3.5-TDP-0.1.0-SNAPSHOT.jar',
    conn_id='spark_default',
    executor_cores=1,
    executor_memory='2g',
    driver_memory='4g',
    total_executor_cores=1,
    name='SparkPi',
    num_executors=1,
    queue='default',
    application_args=['100'],
    dag=dag,
    run_as_user='tdp_user',
)

submit_application
